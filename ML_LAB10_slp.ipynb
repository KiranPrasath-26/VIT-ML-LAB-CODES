{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TA_Q3HKUYCrl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qHMLXgKWcIxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('iris.csv')\n",
        "data.columns=['Sepal_len_cm','Sepal_wid_cm','Petal_len_cm','Petal_wid_cm','Type']\n",
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ASSbE3AecDbo",
        "outputId": "0ad69ce6-c79c-42e0-c02e-046f34dd094b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sepal_len_cm  Sepal_wid_cm  Petal_len_cm  Petal_wid_cm  Type\n",
              "0           5.1           3.5           1.4           0.2     0\n",
              "1           4.9           3.0           1.4           0.2     0\n",
              "2           4.7           3.2           1.3           0.2     0\n",
              "3           4.6           3.1           1.5           0.2     0\n",
              "4           5.0           3.6           1.4           0.2     0\n",
              "5           5.4           3.9           1.7           0.4     0\n",
              "6           4.6           3.4           1.4           0.3     0\n",
              "7           5.0           3.4           1.5           0.2     0\n",
              "8           4.4           2.9           1.4           0.2     0\n",
              "9           4.9           3.1           1.5           0.1     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41bb2331-e06d-40c1-ac61-eb9497338b9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sepal_len_cm</th>\n",
              "      <th>Sepal_wid_cm</th>\n",
              "      <th>Petal_len_cm</th>\n",
              "      <th>Petal_wid_cm</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41bb2331-e06d-40c1-ac61-eb9497338b9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41bb2331-e06d-40c1-ac61-eb9497338b9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41bb2331-e06d-40c1-ac61-eb9497338b9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def activation_func(value):    #Tangent Hypotenuse\n",
        "    #return (1/(1+np.exp(-value)))\n",
        "    return ((np.exp(value)-np.exp(-value))/(np.exp(value)+np.exp(-value)))"
      ],
      "metadata": {
        "id": "J30XMdeeYGeg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_train(in_data,labels,alpha):\n",
        "    X=np.array(in_data)\n",
        "    y=np.array(labels)\n",
        "    weights=np.random.random(X.shape[1])\n",
        "    original=weights\n",
        "    bias=np.random.random_sample()\n",
        "    for key in range(X.shape[0]):\n",
        "        a=activation_func(np.matmul(np.transpose(weights),X[key]))     \n",
        "        yn=0\n",
        "        if a>=0.7:\n",
        "            yn=1\n",
        "        elif a<=(-0.7):\n",
        "            yn=-1\n",
        "        weights=weights+alpha*(yn-y[key])*X[key]\n",
        "        print('Iteration '+str(key)+': '+str(weights))\n",
        "    print('Difference: '+str(weights-original))\n",
        "    return weights"
      ],
      "metadata": {
        "id": "3khbfFj1YmRC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_test(in_data,label_shape,weights):\n",
        "    X=np.array(in_data)\n",
        "    y=np.zeros(label_shape)\n",
        "    for key in range(X.shape[1]):\n",
        "        a=activation_func((weights*X[key]).sum())\n",
        "        y[key]=0\n",
        "        if a>=0.7:\n",
        "            y[key]=1\n",
        "        elif a<=(-0.7):\n",
        "            y[key]=-1\n",
        "    return y"
      ],
      "metadata": {
        "id": "EwniitBEYoqQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(result,labels):\n",
        "    difference=result-np.array(labels)                                                        \n",
        "    correct_ctr=0\n",
        "    for elem in range(difference.shape[0]):\n",
        "        if difference[elem]==0:\n",
        "            correct_ctr+=1\n",
        "    score=correct_ctr*100/difference.size\n",
        "    print('Score='+str(score))"
      ],
      "metadata": {
        "id": "fAx38KEoYsNg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing DataFrame \"data\" into \"d_train\" (60%) and \"d_test\" (40%)\n",
        "divider = np.random.rand(len(data)) < 0.70\n",
        "d_train=data[divider]\n",
        "d_test=data[~divider]"
      ],
      "metadata": {
        "id": "5LplKOEFYuVI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing d_train into data and labels/targets\n",
        "d_train_y=d_train['Type']\n",
        "d_train_X=d_train.drop(['Type'],axis=1)\n",
        "\n",
        "# Dividing d_train into data and labels/targets\n",
        "d_test_y=d_test['Type']\n",
        "d_test_X=d_test.drop(['Type'],axis=1)"
      ],
      "metadata": {
        "id": "RiWpGAN9Yu7A"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate\n",
        "alpha = 0.01\n",
        "\n",
        "# Train\n",
        "weights = perceptron_train(d_train_X, d_train_y, alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP0_0BHHYylg",
        "outputId": "c6b5193d-34d0-43d0-d30c-49fb26fcd65a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: [0.49805674 0.66418795 0.57934896 0.18420975]\n",
            "Iteration 1: [0.54505674 0.69618795 0.59234896 0.18620975]\n",
            "Iteration 2: [0.59105674 0.72718795 0.60734896 0.18820975]\n",
            "Iteration 3: [0.64505674 0.76618795 0.62434896 0.19220975]\n",
            "Iteration 4: [0.69105674 0.80018795 0.63834896 0.19520975]\n",
            "Iteration 5: [0.74105674 0.83418795 0.65334896 0.19720975]\n",
            "Iteration 6: [0.78505674 0.86318795 0.66734896 0.19920975]\n",
            "Iteration 7: [0.83405674 0.89418795 0.68234896 0.20020975]\n",
            "Iteration 8: [0.88805674 0.93118795 0.69734896 0.20220975]\n",
            "Iteration 9: [0.93105674 0.96118795 0.70834896 0.20320975]\n",
            "Iteration 10: [0.98905674 1.00118795 0.72034896 0.20520975]\n",
            "Iteration 11: [1.04605674 1.04518795 0.73534896 0.20920975]\n",
            "Iteration 12: [1.10005674 1.08418795 0.74834896 0.21320975]\n",
            "Iteration 13: [1.15105674 1.11918795 0.76234896 0.21620975]\n",
            "Iteration 14: [1.20805674 1.15718795 0.77934896 0.21920975]\n",
            "Iteration 15: [1.25905674 1.19518795 0.79434896 0.22220975]\n",
            "Iteration 16: [1.31305674 1.22918795 0.81134896 0.22420975]\n",
            "Iteration 17: [1.36405674 1.26618795 0.82634896 0.22820975]\n",
            "Iteration 18: [1.41505674 1.29918795 0.84334896 0.23320975]\n",
            "Iteration 19: [1.46505674 1.32918795 0.85934896 0.23520975]\n",
            "Iteration 20: [1.51505674 1.36318795 0.87534896 0.23920975]\n",
            "Iteration 21: [1.56705674 1.39718795 0.88934896 0.24120975]\n",
            "Iteration 22: [1.61405674 1.42918795 0.90534896 0.24320975]\n",
            "Iteration 23: [1.66805674 1.46318795 0.92034896 0.24720975]\n",
            "Iteration 24: [1.71705674 1.49418795 0.93534896 0.24920975]\n",
            "Iteration 25: [1.76705674 1.52618795 0.94734896 0.25120975]\n",
            "Iteration 26: [1.82205674 1.56118795 0.96034896 0.25320975]\n",
            "Iteration 27: [1.86605674 1.59118795 0.97334896 0.25520975]\n",
            "Iteration 28: [1.91705674 1.62518795 0.98834896 0.25720975]\n",
            "Iteration 29: [1.96205674 1.64818795 1.00134896 0.26020975]\n",
            "Iteration 30: [2.00605674 1.68018795 1.01434896 0.26220975]\n",
            "Iteration 31: [2.05705674 1.71818795 1.03334896 0.26620975]\n",
            "Iteration 32: [2.10505674 1.74818795 1.04734896 0.26920975]\n",
            "Iteration 33: [2.15605674 1.78618795 1.06334896 0.27120975]\n",
            "Iteration 34: [2.20205674 1.81818795 1.07734896 0.27320975]\n",
            "Iteration 35: [2.25205674 1.85118795 1.09134896 0.27520975]\n",
            "Iteration 36: [2.39205674 1.91518795 1.18534896 0.30320975]\n",
            "Iteration 37: [2.52005674 1.97918795 1.27534896 0.33320975]\n",
            "Iteration 38: [2.65805674 2.04118795 1.37334896 0.36320975]\n",
            "Iteration 39: [2.76805674 2.08718795 1.45334896 0.38920975]\n",
            "Iteration 40: [2.89805674 2.14318795 1.54534896 0.41920975]\n",
            "Iteration 41: [3.01205674 2.19918795 1.63534896 0.44520975]\n",
            "Iteration 42: [3.13805674 2.26518795 1.72934896 0.47720975]\n",
            "Iteration 43: [3.23605674 2.31318795 1.79534896 0.49720975]\n",
            "Iteration 44: [3.33605674 2.35318795 1.86534896 0.51720975]\n",
            "Iteration 45: [3.45405674 2.41318795 1.94934896 0.54720975]\n",
            "Iteration 46: [3.56605674 2.47118795 2.02134896 0.57320975]\n",
            "Iteration 47: [3.70005674 2.53318795 2.10934896 0.60120975]\n",
            "Iteration 48: [3.81205674 2.59318795 2.19934896 0.63120975]\n",
            "Iteration 49: [3.92805674 2.64718795 2.28134896 0.65120975]\n",
            "Iteration 50: [4.04005674 2.69718795 2.35934896 0.67320975]\n",
            "Iteration 51: [4.15805674 2.76118795 2.45534896 0.70920975]\n",
            "Iteration 52: [4.28005674 2.81718795 2.53534896 0.73520975]\n",
            "Iteration 53: [4.40605674 2.86718795 2.63334896 0.76520975]\n",
            "Iteration 54: [4.52805674 2.92318795 2.72734896 0.78920975]\n",
            "Iteration 55: [4.66005674 2.98318795 2.81534896 0.81720975]\n",
            "Iteration 56: [4.79605674 3.03918795 2.91134896 0.84520975]\n",
            "Iteration 57: [4.93005674 3.09918795 3.01134896 0.87920975]\n",
            "Iteration 58: [5.04405674 3.15118795 3.08134896 0.89920975]\n",
            "Iteration 59: [5.15405674 3.19918795 3.15734896 0.92120975]\n",
            "Iteration 60: [5.26405674 3.24718795 3.23134896 0.94120975]\n",
            "Iteration 61: [5.38005674 3.30118795 3.30934896 0.96520975]\n",
            "Iteration 62: [5.50005674 3.35518795 3.41134896 0.99720975]\n",
            "Iteration 63: [5.60805674 3.41518795 3.50134896 1.02720975]\n",
            "Iteration 64: [5.72805674 3.48318795 3.59134896 1.05920975]\n",
            "Iteration 65: [5.85405674 3.52918795 3.67934896 1.08520975]\n",
            "Iteration 66: [5.96405674 3.57918795 3.75934896 1.11120975]\n",
            "Iteration 67: [6.07405674 3.63118795 3.84734896 1.13520975]\n",
            "Iteration 68: [6.19005674 3.68318795 3.92734896 1.15920975]\n",
            "Iteration 69: [6.29005674 3.72918795 3.99334896 1.17920975]\n",
            "Iteration 70: [6.40405674 3.78718795 4.07734896 1.20520975]\n",
            "Iteration 71: [6.50605674 3.83718795 4.13734896 1.22720975]\n",
            "Iteration 72: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 73: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 74: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 75: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 76: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 77: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 78: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 79: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 80: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 81: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 82: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 83: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 84: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 85: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 86: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 87: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 88: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 89: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 90: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 91: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 92: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 93: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 94: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 95: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 96: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 97: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 98: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 99: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 100: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 101: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 102: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 103: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 104: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 105: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 106: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 107: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 108: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 109: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 110: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 111: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 112: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 113: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Iteration 114: [6.62005674 3.89318795 4.21934896 1.25320975]\n",
            "Difference: [6.173 3.264 3.654 1.071]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "result_test=perceptron_test(d_test_X,d_test_y.shape,weights)"
      ],
      "metadata": {
        "id": "plCFBQStYzJg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate score\n",
        "score(result_test,d_test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUtWXDGdY3Do",
        "outputId": "43a8ff9e-991c-41e8-dd92-d4ac06707c97"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score=28.571428571428573\n"
          ]
        }
      ]
    }
  ]
}